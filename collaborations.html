<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Richard Jean So — Collaborations</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 2rem;
      line-height: 1.6;
      color: #333;
    }
    h1, h2 {
      color: #004080;
    }
    nav {
      margin-bottom: 2rem;
    }
    nav a {
      margin-right: 1rem;
      text-decoration: none;
      color: #0066cc;
    }
    nav a:hover {
      text-decoration: underline;
    }
    section {
      margin-bottom: 2rem;
    }
  </style>
</head>
<body>
  <h1>Collaborations</h1>

  <nav>
    <a href="about.html">About</a>
    <a href="projects.html">Projects</a>
    <a href="pubs.html">Key Publications</a>
    <a href="cv.html">CV</a>
    <a href="students.html">Students</a>
    <a href="collaborations.html">Collaborations</a>
  </nav>

  <section>
    <h2>Chicago-Duke Cultural Intelligence Lab</h2>
    <p><strong>Co-directed with Hoyt Long (University of Chicago)</strong></p>
    <p>
      Our lab explores the intersection of AI and culture by developing computational tools that study and model cultural phenomena. We leverage cultural theory and critical insight not only to enrich AI systems but also to better understand AI itself as a cultural system. Recognizing culture as the infrastructure of the social world, we investigate how aesthetics, narrative, and interpretation shape social outcomes—ranging from elections and misinformation to vaccine hesitancy and beyond. This collaborative work aims to reveal the causal and generative power of culture in shaping both society and technology.
    </p>
  </section>

  <section>
    <h2>Humanistic AI Working Group</h2>
    <p><strong>Hosted by the University of Chicago Neubauer Collegium</strong></p>
    <p>
      In response to the rapid rise of large language and generative models, this interdisciplinary group brings together specialists from literature, language, philosophy, history, and related fields to critically engage with the impact of these technologies on humanistic inquiry. The group aims to develop a strategic vision for evaluating generative models on humanities terms, enlist them as collaborators in research, and shape their ethical development and deployment beyond academia. Through a series of workshops and case studies over two years, participants seek to lay the conceptual and methodological foundations for rethinking humanities research in the age of AI.
    </p>
  </section>

  <section>
    <h2>Turing Working Group on Computational Hermeneutics</h2>
    <p>
      This group reconceptualizes generative AI as a cultural technology engaged in interpretation and contextual meaning-making, not just pattern matching. Drawing from hermeneutic theory in the humanities, it views AI systems as “context machines” navigating key interpretive challenges—situatedness, plurality, and negotiation—where meaning is dialogic, multiple, and contested. The framework proposes moving beyond binary right/wrong evaluations toward iterative, human-AI collaborative assessments focused on how meaning is constructed. This approach aims to develop AI systems that actively participate in cultural meaning-making, transforming benchmarks and evaluations to better reflect the complexities of interpretation in creative and conversational contexts.
    </p>
  </section>
</body>
</html>

